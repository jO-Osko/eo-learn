{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Registration transform example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example illustrates how to use a RegistrationTransform to temporally align the frames of an EOPatch using different algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create cloudless timelapse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports from `sentinelhub` and `eolearn` to set up workflow that creates a timelapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "from sentinelhub import BBox, CRS, MimeType, CustomUrlParam\n",
    "\n",
    "from eolearn.mask import AddCloudMaskTask, get_s2_pixel_cloud_detector\n",
    "from eolearn.core import EOPatch, FeatureType, LinearWorkflow\n",
    "from eolearn.features import SimpleFilterTask\n",
    "from eolearn.io import S2L1CWCSInput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up BBox of ROI and time interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTANCE_ID = None\n",
    "\n",
    "roi_bbox = BBox(bbox=[128.689942, 37.656454, 128.722946,  37.677434], crs=CRS.WGS84)\n",
    "# roi_bbox = BBox(bbox=[-6.57257, 37.2732, -5.728, 36.8549], crs=CRS.WGS84)\n",
    "time_interval = ('2015-01-01', '2017-03-01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This predicate function filters the images with a cloud coverage larger than a threshold to ensure images do not contain cloudy pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxCCPredicate:\n",
    "    def __init__(self, maxcc):\n",
    "        self.maxcc = maxcc\n",
    "\n",
    "    def __call__(self, img_cm):\n",
    "        w, h, _ = img_cm.shape\n",
    "        cc = np.sum(img_cm) / (w * h)\n",
    "        return cc <= self.maxcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks of the workflow:\n",
    " * download S2 images (all 13 bands)\n",
    " * run `s2cloudless` to compute cloud masks\n",
    " * filter out images with cloud coverage larger than a given threshold (e.g. 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading model, total used 170 iterations\n"
     ]
    }
   ],
   "source": [
    "wcs_task = S2L1CWCSInput(layer='BANDS-S2-L1C', \n",
    "                         resx='10m',\n",
    "                         resy='10m',\n",
    "                         time_difference=datetime.timedelta(hours=2))\n",
    "\n",
    "cloud_classifier = get_s2_pixel_cloud_detector(all_bands=True)\n",
    "add_clm = AddCloudMaskTask(cloud_classifier, \n",
    "                           'BANDS-S2-L1C', \n",
    "                           cm_size_y='20m',\n",
    "                           cm_size_x='20m', \n",
    "                           cmask_feature='clm', \n",
    "                           cprobs_feature='clp')\n",
    "\n",
    "filter_task = SimpleFilterTask((FeatureType.MASK, 'clm'), MaxCCPredicate(maxcc=0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and execute timelapse as chain of transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "timelapse = LinearWorkflow(wcs_task, add_clm, filter_task)\n",
    "\n",
    "result = timelapse.execute({\n",
    "    wcs_task: {\n",
    "        'bbox': roi_bbox,\n",
    "        'time_interval': time_interval\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get result as an eopatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eopatch_clean = [result[key] for key in result.keys()][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Help function to create GIFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio, os\n",
    "\n",
    "def make_gif(eopatch, project_dir, filename, fps):\n",
    "    \"\"\"\n",
    "    Generates a GIF animation from an EOPatch.\n",
    "    \"\"\"\n",
    "    with imageio.get_writer(os.path.join(project_dir, filename), mode='I', fps=fps) as writer:\n",
    "            for image in eopatch:\n",
    "                writer.append_data(np.array(image[..., [2, 1, 0]], dtype=np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write clean EOPatch to GIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_gif(eopatch=eopatch_clean.data['BANDS-S2-L1C'] * 255, project_dir='.', filename='eopatch_clean.gif', fps=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run registrations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import registrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eolearn.coregistration import ECCRegistration, ThunderRegistration, PointBasedRegistration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The constructor of the Registration objects takes the attribute type, field name and index of the channel to be used for registration, a dictionary specifying the parameters of the registration, and the interpolation method to be applied to the images. The interpolation methods are (NEAREST, LINEAR and CUBIC). Default is CUBIC. A nearest neighbour interpolation is used on ground-truth data to avoid creation of new labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thunder registration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This algorithm computes translations only between pairs of images, using correlation on the Fourier transforms of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:eolearn.coregistration.coregistration:ThunderRegistration:This registration does not require parameters\n"
     ]
    }
   ],
   "source": [
    "coregister_thunder = ThunderRegistration((FeatureType.DATA, 'BANDS-S2-L1C'), channel=2)\n",
    "\n",
    "eopatch_thunder = coregister_thunder(eopatch_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write result to GIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_gif(eopatch=eopatch_thunder.data['BANDS-S2-L1C']*255, project_dir='.', filename='eopatch_thunder.gif', fps=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhanced Cross-Correlation in OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This algorithm uses intensity values to maximise cross-correlation between pair of images. It uses an Euler transformation (x,y translation plus rotation). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:eolearn.coregistration.coregistration:ECCRegistration:Params for this registration are:\n",
      "INFO:eolearn.coregistration.coregistration:\t\t\t\tMaxIters: 200\n"
     ]
    }
   ],
   "source": [
    "params = {'MaxIters': 200}\n",
    "coregister_ecc = ECCRegistration((FeatureType.DATA, 'BANDS-S2-L1C'), channel=2, params=params)\n",
    "\n",
    "eopatch_ecc = coregister_ecc(eopatch_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_gif(eopatch=eopatch_ecc.data['BANDS-S2-L1C']*255, project_dir='.', filename='eopatch_ecc.gif', fps=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Point-Based Registration in OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three transformation models are supported for point-based registration, i.e. Euler, PartialAffine and Homography. These methods compute feature descriptors (i.e. SIFT or SURF) of the pair of images to be registered, and estimate a robust transformation using RANSAC to align the matching points. These methods perform poorly compared to the other methods due to the inaccuracies of the feature extraction, point-matching and model fitting. If unplausible transformations are estimated, a warning is issued and an identity matrix is employed instead of the estimated transform. Default parameters are (Model=Euler, Descriptor=SIFT, RANSACThreshold=7.0, MaxIters=1000).\n",
    "\n",
    "Note: In case the following cell will raise an error\n",
    "\n",
    "```Python\n",
    "AttributeError: module 'cv2.cv2' has no attribute 'xfeatures2d'\n",
    "```\n",
    "\n",
    "uninstall and reinstall Python package `opencv-contrib-python`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:eolearn.coregistration.coregistration:PointBasedRegistration:Model set to Euler\n",
      "INFO:eolearn.coregistration.coregistration:PointBasedRegistration:Descriptor set to SIFT\n",
      "INFO:eolearn.coregistration.coregistration:PointBasedRegistration:RANSAC MaxIters set to 1000\n",
      "INFO:eolearn.coregistration.coregistration:PointBasedRegistration:RANSAC threshold set to 7.0\n",
      "INFO:eolearn.coregistration.coregistration:PointBasedRegistration:Params for this registration are:\n",
      "INFO:eolearn.coregistration.coregistration:\t\t\t\tModel: Euler\n",
      "INFO:eolearn.coregistration.coregistration:\t\t\t\tDescriptor: SIFT\n",
      "INFO:eolearn.coregistration.coregistration:\t\t\t\tMaxIters: 1000\n",
      "INFO:eolearn.coregistration.coregistration:\t\t\t\tRANSACThreshold: 7.00\n",
      "WARNING:eolearn.coregistration.coregistration:PointBasedRegistration warning in pair-wise reg 24 to 25\n",
      "WARNING:eolearn.coregistration.coregistration:PointBasedRegistration warning in pair-wise reg 23 to 24\n",
      "WARNING:eolearn.coregistration.coregistration:PointBasedRegistration warning in pair-wise reg 22 to 23\n",
      "WARNING:eolearn.coregistration.coregistration:PointBasedRegistration warning in pair-wise reg 21 to 22\n",
      "WARNING:eolearn.coregistration.coregistration:PointBasedRegistration warning in pair-wise reg 20 to 21\n",
      "WARNING:eolearn.coregistration.coregistration:PointBasedRegistration warning in pair-wise reg 19 to 20\n",
      "WARNING:eolearn.coregistration.coregistration:PointBasedRegistration warning in pair-wise reg 18 to 19\n",
      "WARNING:eolearn.coregistration.coregistration:PointBasedRegistration warning in pair-wise reg 15 to 16\n",
      "WARNING:eolearn.coregistration.coregistration:PointBasedRegistration warning in pair-wise reg 14 to 15\n",
      "WARNING:eolearn.coregistration.coregistration:PointBasedRegistration warning in pair-wise reg 11 to 12\n",
      "WARNING:eolearn.coregistration.coregistration:PointBasedRegistration warning in pair-wise reg 9 to 10\n",
      "WARNING:eolearn.coregistration.coregistration:PointBasedRegistration warning in pair-wise reg 8 to 9\n",
      "WARNING:eolearn.coregistration.coregistration:PointBasedRegistration warning in pair-wise reg 7 to 8\n",
      "WARNING:eolearn.coregistration.coregistration:PointBasedRegistration warning in pair-wise reg 3 to 4\n",
      "WARNING:eolearn.coregistration.coregistration:PointBasedRegistration warning in pair-wise reg 2 to 3\n",
      "WARNING:eolearn.coregistration.coregistration:PointBasedRegistration warning in pair-wise reg 0 to 1\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'Model': 'Euler',\n",
    "    'Descriptor': 'SURF',\n",
    "    'RANSACThreshold': 7.0,\n",
    "    'MaxIters': 1000\n",
    "}\n",
    "\n",
    "coregister_pbased = PointBasedRegistration((FeatureType.DATA, 'BANDS-S2-L1C'), channel=2, params=params)\n",
    "\n",
    "eopatch_pbased = coregister_pbased(eopatch_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_gif(eopatch=eopatch_pbased.data['BANDS-S2-L1C']*255, project_dir='.', filename='eopatch_pbased.gif', fps=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
